{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auction\n",
    "* 500 Buyers\n",
    "* \\# Painint Train / Test: 2000 / 1000\n",
    "* Choose top-10\n",
    "* Evaluation Metric: Rate of choosing the top-K (Recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "* Negative values in price????????????????????????????????????????????\n",
    "* Number of testing paining are NOT 1000 ????????????????????????????????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BUYER = 500\n",
    "NUM_TRAIN = 2000\n",
    "NUM_TEST = 1000 - 1\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "\n",
    "\n",
    "def read_price(f_name):    \n",
    "    with open(f_name, 'r') as f:\n",
    "        data = np.array([list(map(float, line.strip().split(' '))) for line in f])\n",
    "    assert len(data) == NUM_BUYER\n",
    "    assert data.shape[1] == (NUM_TRAIN if 'train' in f_name else NUM_TEST)\n",
    "    return data\n",
    "\n",
    "    \n",
    "def read_category(f_name):    \n",
    "    with open(f_name, 'r') as f:\n",
    "        data = np.array([int(e.strip()) for e in f.readlines()])\n",
    "    assert len(data) == NUM_TRAIN if 'train' in f_name else NUM_TEST\n",
    "    return data\n",
    "\n",
    "\n",
    "def scale_to_origin(train, test):\n",
    "    grand_min = min(np.min(train), np.min(test))\n",
    "    if grand_min >= 0:\n",
    "        print(f\"Min price: {grand_min} is already above 0\")\n",
    "    train -= grand_min\n",
    "    test -= grand_min\n",
    "    assert min(np.min(train), np.min(test)) == 0\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def get_win_buyer(data):\n",
    "    return np.argmax(data, axis=0)\n",
    "\n",
    "\n",
    "def boradcast_const_pred(pred, k, num_test=NUM_TEST):\n",
    "    return np.tile(pred, reps=num_test).reshape(num_test, -1)\n",
    "\n",
    "\n",
    "def get_mean_pred(train, k, num_test):\n",
    "    return boradcast_const_pred(train.mean(1).argsort()[::-1][:k], k, num_test)\n",
    "\n",
    "\n",
    "def recall(pred, ans):\n",
    "    assert len(pred) == len(ans)\n",
    "    return np.array([a in topk for a, topk in zip(ans, pred)]).mean()\n",
    "\n",
    "\n",
    "def get_user_features(train, n_components=128, method='NMF'):\n",
    "    mf_model = eval(method)(n_components=n_components)\n",
    "    user_features = mf_model.fit_transform(train)\n",
    "    return user_features\n",
    "\n",
    "\n",
    "def get_cls_pred(train, user_features, k, n_pick_per_cls):\n",
    "    n_clusters = k // n_pick_per_cls\n",
    "    cls_model = KMeans(n_clusters=n_clusters, n_jobs=-1).fit(user_features)\n",
    "\n",
    "    bucket = [[] for _ in range(cls_model.n_clusters)]\n",
    "    pred = []\n",
    "    for u_id, c_id in enumerate(cls_model.predict(user_features)):\n",
    "        bucket[c_id].append(u_id) \n",
    "    for user_ids in bucket:\n",
    "        user_ids = np.array(user_ids)\n",
    "        pred.extend(user_ids[train[user_ids].mean(1).argsort()[-n_pick_per_cls:]])\n",
    "    return pred\n",
    "\n",
    "\n",
    "def get_gmm_pred(train, user_features, k, n_pick_per_cls):\n",
    "    n_components = k // n_pick_per_cls\n",
    "    gmm = GaussianMixture(n_components=n_components).fit(user_features)\n",
    "    prob = gmm.predict_proba(user_features)\n",
    "    \n",
    "    bucket = [[] for _ in range(gmm.n_components)]\n",
    "    pred = []\n",
    "    for u_id, c_id in enumerate(gmm.predict(user_features)):\n",
    "        bucket[c_id].append(u_id) \n",
    "    for user_ids in bucket:\n",
    "        user_ids = np.array(user_ids)\n",
    "        pred.extend(user_ids[train[user_ids].mean(1).argsort()[-n_pick_per_cls:]])\n",
    "    return pred\n",
    "\n",
    "\n",
    "def result(pred_dict, test, k=10):\n",
    "#     assert all([len(pred[0]) == k for _, pred in pred_dict.items()])\n",
    "    ans = get_win_buyer(test)\n",
    "    pred_random_test = np.random.randint(k, size=(len(test[0]), k))\n",
    "\n",
    "    recall_random_test = recall(pred_random_test, ans)\n",
    "    recall_random_theory = k / len(test)\n",
    "\n",
    "    print(f\"Recall@{k}\\n\"\n",
    "          f\"Random:\\t\\t\\t{100 * recall_random_test:.6f}%\\n\"\n",
    "          f\"Random (theory):\\t{100 * recall_random_theory:.6f}%\\n\" +\n",
    "          f\"\".join([f\"{name}\\t\\t\\t{100 * recall(boradcast_const_pred(pred, k, len(test[0])), ans):.6f}%\\n\" for name, pred in pred_dict.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_price('Auction/basic-train.txt')\n",
    "test = read_price('Auction/basic-test.txt')\n",
    "train, test = scale_to_origin(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = get_user_features(train, n_components=64, method='NMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@2\n",
      "Random:\t\t\t0.000000%\n",
      "Random (theory):\t0.400000%\n",
      "Mean\t\t\t5.405405%\n",
      "Cls\t\t\t5.405405%\n",
      "Gmm\t\t\t5.405405%\n",
      "\n",
      "Recall@6\n",
      "Random:\t\t\t1.101101%\n",
      "Random (theory):\t1.200000%\n",
      "Mean\t\t\t10.210210%\n",
      "Cls\t\t\t10.810811%\n",
      "Gmm\t\t\t9.209209%\n",
      "\n",
      "Recall@10\n",
      "Random:\t\t\t1.501502%\n",
      "Random (theory):\t2.000000%\n",
      "Mean\t\t\t15.315315%\n",
      "Cls\t\t\t13.313313%\n",
      "Gmm\t\t\t14.114114%\n",
      "\n",
      "Recall@20\n",
      "Random:\t\t\t2.702703%\n",
      "Random (theory):\t4.000000%\n",
      "Mean\t\t\t22.622623%\n",
      "Cls\t\t\t18.018018%\n",
      "Gmm\t\t\t20.720721%\n",
      "\n",
      "Recall@40\n",
      "Random:\t\t\t6.106106%\n",
      "Random (theory):\t8.000000%\n",
      "Mean\t\t\t33.733734%\n",
      "Cls\t\t\t29.429429%\n",
      "Gmm\t\t\t31.131131%\n",
      "\n",
      "Recall@60\n",
      "Random:\t\t\t7.007007%\n",
      "Random (theory):\t12.000000%\n",
      "Mean\t\t\t42.642643%\n",
      "Cls\t\t\t36.336336%\n",
      "Gmm\t\t\t32.532533%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_pick_per_cls = 2\n",
    "for k in [1, 3, 5, 10, 20, 30]:\n",
    "    k *= n_pick_per_cls\n",
    "    result({'Mean': get_mean_pred(train, k, len(test[1])),\n",
    "            'Cls': get_cls_pred(train, user_features, k, n_pick_per_cls),\n",
    "            'Gmm': get_gmm_pred(train, user_features, k, n_pick_per_cls)\n",
    "           },\n",
    "           test,\n",
    "           k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    677\n",
       "3    669\n",
       "2    654\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3    342\n",
       "2    334\n",
       "1    323\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = read_price('Auction/advanced-train.txt')\n",
    "test = read_price('Auction/advanced-test.txt')\n",
    "cat_train = read_category('Auction/advanced-train-category.txt')\n",
    "cat_test = read_category('Auction/advanced-test-category.txt')\n",
    "\n",
    "train, test = scale_to_origin(train, test)\n",
    "\n",
    "train = {k: train[:, cat_train==k] for k in [1, 2, 3]}\n",
    "# test = {k: test[:, cat_test==k] for k in [1, 2, 3]}\n",
    "\n",
    "display(pandas.Series(cat_train).value_counts())\n",
    "display(pandas.Series(cat_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'NMF'\n",
    "n_components = 32\n",
    "user_features = {k: get_user_features(mat, n_components, method) for k, mat in train.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@2\n",
      "Random:\t\t\t0.400400%\n",
      "Random (theory):\t0.400000%\n",
      "Mean\t\t\t4.104104%\n",
      "Cls\t\t\t4.104104%\n",
      "Gmm\t\t\t4.104104%\n",
      "\n",
      "Recall@6\n",
      "Random:\t\t\t0.200200%\n",
      "Random (theory):\t1.200000%\n",
      "Mean\t\t\t9.109109%\n",
      "Cls\t\t\t8.808809%\n",
      "Gmm\t\t\t8.408408%\n",
      "\n",
      "Recall@8\n",
      "Random:\t\t\t1.101101%\n",
      "Random (theory):\t1.600000%\n",
      "Mean\t\t\t11.311311%\n",
      "Cls\t\t\t10.710711%\n",
      "Gmm\t\t\t11.011011%\n",
      "\n",
      "Recall@10\n",
      "Random:\t\t\t0.700701%\n",
      "Random (theory):\t2.000000%\n",
      "Mean\t\t\t13.113113%\n",
      "Cls\t\t\t12.112112%\n",
      "Gmm\t\t\t11.911912%\n",
      "\n",
      "Recall@20\n",
      "Random:\t\t\t2.302302%\n",
      "Random (theory):\t4.000000%\n",
      "Mean\t\t\t20.120120%\n",
      "Cls\t\t\t19.719720%\n",
      "Gmm\t\t\t20.120120%\n",
      "\n",
      "Recall@40\n",
      "Random:\t\t\t4.304304%\n",
      "Random (theory):\t8.000000%\n",
      "Mean\t\t\t30.630631%\n",
      "Cls\t\t\t29.029029%\n",
      "Gmm\t\t\t28.528529%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def combine_mean(k):\n",
    "    pred = np.empty((NUM_TEST, k))\n",
    "    pred[cat_test==1] = get_mean_pred(train[1], k, sum(cat_test==1))\n",
    "    pred[cat_test==2] = get_mean_pred(train[2], k, sum(cat_test==2))\n",
    "    pred[cat_test==3] = get_mean_pred(train[3], k, sum(cat_test==3))\n",
    "    return pred\n",
    "\n",
    "def combine_cls(k, n_pick_per_cls):\n",
    "    pred = np.empty((NUM_TEST, k))\n",
    "    for part in [1, 2, 3]:\n",
    "        pred[cat_test==part] = get_cls_pred(train[part], user_features[part], k, n_pick_per_cls)\n",
    "    return pred\n",
    "\n",
    "def combine_gmm(k, n_pick_per_cls):\n",
    "    pred = np.empty((NUM_TEST, k))\n",
    "    for part in [1, 2, 3]:\n",
    "        pred[cat_test==part] = get_gmm_pred(train[part], user_features[part], k, n_pick_per_cls)\n",
    "    return pred\n",
    "\n",
    "n_pick_per_cls = 2\n",
    "for k in [1, 3, 4, 5, 10, 20]:\n",
    "    k *= n_pick_per_cls\n",
    "    result({'Mean': combine_mean(k),\n",
    "            'Cls': combine_cls(k, n_pick_per_cls),\n",
    "            'Gmm': combine_gmm(k, n_pick_per_cls)\n",
    "           },\n",
    "           test,\n",
    "           k=k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
